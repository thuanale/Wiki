1. Cloud Functions 
- Create a bucket for storing the photographs.
- Create a Pub/Sub topic that will be used by a Cloud Function you create.
- Create a Cloud Function to trigger whenever an image/object is created on
bucket.
- Remove the previous cloud engineer’s access from the memories project.

2. Terraform:
- Task 1: Import existing infrastructure into your Terraform configuration.
  - Create tree:

main.tf
variables.tf
modules/
└── instances
    ├── instances.tf
    ├── outputs.tf
    └── variables.tf
└── storage
    ├── storage.tf
    ├── outputs.tf
    └── variables.tf

  - Fill out the variables.tf files in the root directory and within the
    modules. 
      - Add three variables to each file: region, zone, and project_id.
      - For their default values, use us-east1, us-east1-b , and your Google
        Cloud Project ID.
      - Note: You should use these variables anywhere applicable in your
        resource configurations.
  - Add the Terraform block and the Google Provider to the main.tf file. Verify the zone argument is added along with the project and region arguments in the Google Provider block.
  - Initialize Terraform.    

- Task2: Build and reference your own Terraform modules.
  - In the Google Cloud Console, on the Navigation menu, click Compute Engine >
    VM Instances. Two instances named tf-instance-1 and tf-instance-2 have
    already been created for you.
  - Note: by clicking on one of the instances, you can find its Instance ID,
    boot disk image, and machine type. These are all necessary for writing the
    configurations correctly and importing them into Terraform.
  - Import the existing instances into the instances module. To do this, you
    will need to follow these steps:
  - First, add the module reference into the main.tf file then re-initialize
    Terraform.
  - Next, write the resource configurations in the instances.tf file to match
    the pre-existing instances.
  - Name your instances tf-instance-1 and tf-instance-2.
  - For the purposes of this lab, the resource configuration should be as
    minimal as possible.
    - To accomplish this, you will only need to include the following
      additional arguments in your configuration: machine_type, boot_disk,
      network_interface, metadata_startup_script, and
      allow_stopping_for_update.
    - For the last two arguments, use the following configuration as this will
      ensure you won't need to recreate it:

metadata_startup_script = <<-EOT
        #!/bin/bash
    EOT
allow_stopping_for_update = true

  - Once you have written the resource configurations within the module, use
    the terraform import command to import them into your instances module.
  - Apply your changes. Note that since you did not fill out all of the
    arguments in the entire configuration, the apply will update the instances
    in-place. This is fine for lab purposes, but in a production environment,
    you should make sure to fill out all of the arguments correctly before
    importing.

- Task 3: Add a remote backend to your configuration.
  - Create a Cloud Storage bucket resource inside the storage module.
      - bucket name: tf-bucket-195245
      - location = "US"
      - force_destroy = true
      - uniform_bucket_level_access = true
      - Note: You can optionally add output values inside of the outputs.tf file.
  - Add the module reference to the main.tf file. Initialize the module and
    apply the changes to create the bucket using Terraform.
  - Configure this storage bucket as the remote backend inside the main.tf
    file. Be sure to use the prefix terraform/state so it can be graded
    successfully.
  - If you've written the configuration correctly, upon init, Terraform will
    ask whether you want to copy the existing state data to the new backend.
    Type yes at the prompt.

- Task 4: Modify & update infrastructure:
  - Navigate to the instances module and modify the tf-instance-1 resource to
    use an n1-standard-2 machine type.
  - Modify the tf-instance-2 resource to use an n1-standard-2 machine type.
  - Add a third instance resource and name it tf-instance-491345 . For this
    third resource, use an n1-standard-2 machine type.
  - Initialize Terraform and apply your changes.

- Task 5: Taint and destroy resources.
  - Taint the third instance tf-instance-491345 , and then plan and apply your
    changes to to recreate it.
  - Destroy the third instance tf-instance-491345 by removing the resource from
    the configuration file. After removing it, initialize terraform and apply
    the changes.

- Task 6: Use and implement a module from the Terraform Registry.
  - In the Terraform Registry, browse to the Network Module.
  - Add this module to your main.tf file. Use the following configurations:
    - Use version 3.4.0 (different versions might cause compatibility errors).
    - Name the VPC tf-vpc-745521 , and use a global routing mode.
    - Specify 2 subnets in the us-east1 region, and name them subnet-01 and
      subnet-02.
      - For the subnets arguments, you just need the Name, IP, and Region.
      - Use the IP 10.10.10.0/24 for subnet-01, and 10.10.20.0/24 for
        subnet-02.
       - You do not need any secondary ranges or routes associated with this
         VPC, so you can omit them from the configuration.
  - Once you've written the module configuration, initialize Terraform and run
    an apply to create the networks.
  - Next, navigate to the instances.tf file and update the configuration
    resources to connect tf-instance-1 to subnet-01 and tf-instance-2 to
    subnet-02.
  - Note: Within the instance configuration, you will need to update the
    network argument to tf-vpc-745521 , and then add the subnetwork argument
    with the correct subnet for each instance.

- Task 7: Configure firewall:
  - Create a firewall rule resource in the main.tf file, and name it tf-firewall.
    - This firewall rule should permit the tf-vpc-745521 network to allow
      ingress connections on all IP ranges (0.0.0.0/0) on TCP port 80..
    - Make sure you add the source_ranges argument with the correct IP range
      (0.0.0.0/0).
  - Initialize Terraform and apply your changes.
  - Note: To retrieve the required network argument, you can inspect the state
    and find the ID or self_link of the google_compute_network resource you
    created. It will be in the form projects/PROJECT_ID/global/networks/
    tf-vpc-745521 .

- Task 8: Test connectivity between the resources you've created.
  - After you have created a firewall rule to allow internal connections over
    the VPC, you can optionally run a network connectivity test.
  - Make sure both of your VMs are running.
  - Navigate to Network Intelligence > Connectivity Tests. Run a connectivity
    test on the two VMs to verify that they are reachable. You have now
    validated the connectivity between the instances!
  - Note: Ensure that the Network Management API is successfully enabled; if it
    is not, click Enable.
